{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#elroy-an-ai-assistant-that-remembers-and-sets-goals","title":"Elroy: An AI assistant that remembers and sets goals","text":"<p>Elroy is an AI assistant that runs in your terminal, with memory and powerful goal tracking. It remembers everything you tell it, can learn from your documents, and helps you stay organized.</p> <p></p>"},{"location":"#features","title":"Features","text":"<ul> <li>Memory: Elroy automatically recalls relevant information from past conversations</li> <li>Goal Tracking System: Create, update, and track personal and professional goals</li> <li>Codebase Understanding: Ingest your repositories to give Elroy context about your projects</li> <li>Simple Scripting: Automate tasks with minimal configuration overhead</li> <li>CLI Tool Interface: Quickly review memories or jot notes for Elroy to remember</li> <li>MCP Server: Surface conversation memories to other tools via Model Context Protocol</li> </ul> <p>The fastest way to get started is using the install script:</p> <pre><code>curl -LsSf https://raw.githubusercontent.com/elroy-bot/elroy/main/scripts/install.sh | sh\n</code></pre> <p>Or install manually with UV:</p> <pre><code># Install UV first\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Then install Elroy\nuv pip install elroy\n</code></pre> <p>For detailed installation instructions including Docker and source installation options, see our Installation Guide.</p>"},{"location":"#elroy-from-your-terminal","title":"Elroy from your terminal","text":"<p>Elroy runs in your terminal helps you with goals while maintaining memory of your interactions. As you chat with Elroy, it automatically:</p> <ol> <li>Creates memories of important information</li> <li>Recalls relevant context when needed</li> <li>Tracks goals you set together</li> <li>Consolidates redundant information to keep context clean</li> </ol>"},{"location":"#quickstart","title":"Quickstart","text":"<p>Run the install script: <pre><code>curl -LsSf https://raw.githubusercontent.com/elroy-bot/elroy/main/scripts/uv-installer.sh | sh\n</code></pre></p> <p>Ensure your env has <code>ANTHROPIC_API_KEY</code>, <code>OPENAI_API_KEY</code> or whatever model provider token you wish to use is set.</p> <pre><code># Start the chat interface\nelroy\n\n# Run with a specific model\nelroy --chat-model \"gemini/gemini-2.0-flash\"\n\n# To see more detailed CLI options\nelroy --help\n</code></pre>"},{"location":"#slash-commands","title":"Slash Commands","text":"<p>Elroy's CLI supports slash commands for quick actions. Some examples (run <code>/help</code> to see the full list):</p> <pre><code># Create a memory\n/create_memory This is important information I want to save\n\n# Create a goal\n/create_goal Learn how to use Elroy effectively\n\n# Process a single message and exit\nelroy message \"Say hello world\"\n\n# Force use of a specific tool\nelroy message \"Create a goal\" --tool create_goal\n</code></pre>"},{"location":"#scripting-with-elroy","title":"Scripting with Elroy","text":"<p>Elroy can be used in scripts and automated workflows:</p> <pre><code>from elroy import Elroy\n\nai = Elroy()\n\n# Create a memory\nai.remember(\"Important project context\")\n\n# Process a message with memory augmentation\nresponse = ai.message(\"What should I do next on the project?\")\nprint(response)\n</code></pre>"},{"location":"#supported-models","title":"Supported Models","text":"<p>Elroy works with:</p> <ul> <li>OpenAI: GPT-4o, GPT-4o-mini, o1, o1-mini</li> <li>Anthropic: Claude 3.5 Sonnet, Claude 3 Opus</li> <li>Google: Gemini</li> <li>Any OpenAI-compatible API</li> </ul> <p>Under the hood, Elroy uses LiteLLM to interface with model providers.</p>"},{"location":"#community","title":"Community","text":"<p>Come say hello!</p> <ul> <li>Discord</li> <li>GitHub</li> </ul>"},{"location":"#license","title":"License","text":"<p>Distributed under the Apache 2.0 license. See LICENSE for more information.</p>"},{"location":"cli/","title":"CLI","text":"<p>Elroy provides a powerful command-line interface that makes it easy to interact with the AI assistant directly from your terminal.</p>"},{"location":"cli/#basic-usage","title":"Basic Usage","text":"<pre><code># Start the chat interface\nelroy chat\n\n# Or just 'elroy' which defaults to chat mode\nelroy\n\n# Process a single message and exit\nelroy message \"Say hello world\"\n\n# Create a memory\nelroy remember \"This is important information I want to save\"\n</code></pre>"},{"location":"cli/#slash-commands","title":"Slash Commands","text":"<p>Elroy supports powerful slash commands for quick actions:</p> <pre><code># Create a memory\n/create_memory This is important information I want to save\n\n# Create a goal\n/create_goal Learn how to use Elroy effectively\n</code></pre> <p>For a full list of available tools and slash commands, see the Tools Guide.</p>"},{"location":"cli/#command-reference","title":"Command Reference","text":"Command Description <code>elroy chat</code> Opens an interactive chat session (default command) <code>elroy message TEXT</code> Process a single message and exit <code>elroy remember [TEXT]</code> Create a new memory from text or interactively <code>elroy list-models</code> Lists supported chat models and exits <code>elroy list-tools</code> Lists all available tools <code>elroy print-config</code> Shows current configuration and exits <code>elroy version</code> Show version and exit <code>elroy print-tool-schemas</code> Prints the schema for a tool and exits <code>elroy set-persona TEXT</code> Set a custom persona for the assistant <code>elroy reset-persona</code> Removes any custom persona, reverting to the default <code>elroy show-persona</code> Print the system persona and exit <code>elroy mcp</code> MCP server commands"},{"location":"cli/#shell-integration","title":"Shell Integration","text":"<p>Elroy can be used in scripts and automated workflows:</p> <pre><code># Process a single question\necho \"What is 2+2?\" | elroy chat\n\n# Create a memory from file content\ncat meeting_notes.txt | elroy remember\n\n# Use a specific tool with piped input\necho \"Buy groceries\" | elroy message --tool create_goal\n</code></pre> <p>For more detailed information about configuration options and flags, see the Configuration page.</p>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#configuration-methods","title":"Configuration Methods","text":"<p>Elroy's configuration can be specified in three ways, in order of precedence:</p> <ol> <li> <p>Command Line Flags: Highest priority, overrides all other settings    <pre><code>elroy --chat-model claude-3-5-sonnet-20241022\n</code></pre></p> </li> <li> <p>Environment Variables: Second priority, overridden by CLI flags. All environment variables are prefixed with <code>ELROY_</code> and use uppercase with underscores:    <pre><code>export ELROY_CHAT_MODEL=gpt-4o\nexport ELROY_DEBUG=1\n</code></pre></p> </li> <li> <p>Configuration File: Lowest priority, overridden by both CLI flags and environment variables    <pre><code># ~/.config/elroy/config.yaml\nchat_model: gpt-4o\ndebug: true\n</code></pre></p> </li> </ol> <p>The configuration file location can be specified with the <code>--config</code> flag or defaults to <code>~/.config/elroy/config.yaml</code>.</p> <p>For default config values, see defaults.yml</p>"},{"location":"configuration/#commands","title":"Commands","text":"<ul> <li><code>elroy chat</code> - Opens an interactive chat session (default command)</li> <li><code>elroy message TEXT</code> - Process a single message and exit</li> <li><code>elroy remember [TEXT]</code> - Create a new memory from text or interactively</li> <li><code>elroy list-models</code> - Lists supported chat models and exits</li> <li><code>elroy list-tools</code> - Lists all available tools</li> <li><code>elroy print-config</code> - Shows current configuration and exits</li> <li><code>elroy version</code> - Show version and exit</li> <li><code>elroy print-tool-schemas</code> - Prints the schema for a tool and exits</li> <li><code>elroy set-persona TEXT</code> - Set a custom persona for the assistant</li> <li><code>elroy reset-persona</code> - Removes any custom persona, reverting to the default</li> <li><code>elroy show-persona</code> - Print the system persona and exit</li> <li><code>elroy mcp</code> - MCP server commands</li> </ul> <p>Note: Running just <code>elroy</code> without any command will default to <code>elroy chat</code>.</p>"},{"location":"configuration/#configuration-options","title":"Configuration Options","text":"<p>Note: All configuration options can be set via environment variables with the prefix <code>ELROY_</code> (e.g.,<code>ELROY_CHAT_MODEL=gpt-4o</code>). The environment variable name is created by converting the option name to uppercase and adding the <code>ELROY_</code> prefix.</p>"},{"location":"configuration/#basic-configuration","title":"Basic Configuration","text":"<ul> <li><code>--config TEXT</code>: YAML config file path. Values override defaults but are overridden by CLI flags and environment variables. [default: ~/.config/elroy/config.yaml]</li> <li><code>--default-assistant-name TEXT</code>: Default name for the assistant. [default: Elroy]</li> <li><code>--debug / --no-debug</code>: Enable fail-fast error handling and verbose logging output. [default: false]</li> <li><code>--user-token TEXT</code>: User token to use for Elroy. [default: DEFAULT]</li> <li><code>--custom-tools-path TEXT</code>: Path to custom functions to load (can be specified multiple times)</li> <li><code>--max-ingested-doc-lines INTEGER</code>: Maximum number of lines to ingest from a document. If a document has more lines, it will be ignored.</li> <li><code>--database-url TEXT</code>: Valid SQLite or Postgres URL for the database. If Postgres, the pgvector extension must be installed.</li> <li><code>--inline-tool-calls / --no-inline-tool-calls</code>: Whether to enable inline tool calls in the assistant (better for some open source models). [default: false]</li> </ul>"},{"location":"configuration/#model-selection-and-configuration","title":"Model Selection and Configuration","text":""},{"location":"configuration/#automatic-model-selection","title":"Automatic Model Selection","text":"<p>Elroy will automatically select appropriate models based on available API keys:</p> API Key Chat Model Embedding Model <code>ANTHROPIC_API_KEY</code> Claude 3 Sonnet text-embedding-3-small <code>OPENAI_API_KEY</code> GPT-4o text-embedding-3-small <code>GEMINI_API_KEY</code> Gemini 2.0 Flash text-embedding-3-small"},{"location":"configuration/#model-configuration-options","title":"Model Configuration Options","text":"Option Description Default <code>--chat-model TEXT</code> The model to use for chat completions Inferred from API keys <code>--chat-model-api-base TEXT</code> Base URL for OpenAI compatible chat model API - <code>--chat-model-api-key TEXT</code> API key for OpenAI compatible chat model API - <code>--embedding-model TEXT</code> The model to use for text embeddings text-embedding-3-small <code>--embedding-model-size INTEGER</code> The size of the embedding model 1536 <code>--embedding-model-api-base TEXT</code> Base URL for OpenAI compatible embedding model API - <code>--embedding-model-api-key TEXT</code> API key for OpenAI compatible embedding model API - <code>--enable-caching / --no-enable-caching</code> Whether to enable caching for the LLM true"},{"location":"configuration/#model-aliases","title":"Model Aliases","text":"<p>Shortcuts for common models:</p> Alias Description <code>--sonnet</code> Use Anthropic's Claude 3 Sonnet model <code>--opus</code> Use Anthropic's Claude 3 Opus model <code>--4o</code> Use OpenAI's GPT-4o model <code>--4o-mini</code> Use OpenAI's GPT-4o-mini model <code>--o1</code> Use OpenAI's o1 model <code>--o1-mini</code> Use OpenAI's o1-mini model"},{"location":"configuration/#context-management","title":"Context Management","text":"<ul> <li><code>--max-assistant-loops INTEGER</code>: Maximum number of loops the assistant can run before tools are temporarily made unavailable (returning for the next user message). [default: 4]</li> <li><code>--max-tokens INTEGER</code>: Number of tokens that triggers a context refresh and compression of messages in the context window. [default: 10000]</li> <li><code>--max-context-age-minutes FLOAT</code>: Maximum age in minutes to keep. Messages older than this will be dropped from context, regardless of token limits. [default: 720]</li> <li><code>--min-convo-age-for-greeting-minutes FLOAT</code>: Minimum age in minutes of conversation before the assistant will offer a greeting on login. 0 means assistant will offer greeting each time. To disable greeting, set --first=True (This will override any value for min_convo_age_for_greeting_minutes). [default: 120]</li> <li><code>--first</code>: If true, assistant will not send the first message.</li> </ul>"},{"location":"configuration/#memory-consolidation","title":"Memory Consolidation","text":"<ul> <li><code>--memories-between-consolidation INTEGER</code>: How many memories to create before triggering a memory consolidation operation. [default: 4]</li> <li><code>--l2-memory-relevance-distance-threshold FLOAT</code>: L2 distance threshold for memory relevance. [default: 1.24]</li> <li><code>--memory-cluster-similarity-threshold FLOAT</code>: Threshold for memory cluster similarity. The lower the parameter is, the less likely memories are to be consolidated. [default: 0.21125]</li> <li><code>--max-memory-cluster-size INTEGER</code>: The maximum number of memories that can be consolidated into a single memory at once. [default: 5]</li> <li><code>--min-memory-cluster-size INTEGER</code>: The minimum number of memories that can be consolidated into a single memory at once. [default: 3]</li> </ul>"},{"location":"configuration/#ui-configuration","title":"UI Configuration","text":"<ul> <li><code>--show-internal-thought / --no-show-internal-thought</code>: Show the assistant's internal thought monologue. [default: true]</li> <li><code>--system-message-color TEXT</code>: Color for system messages. [default: #9ACD32]</li> <li><code>--user-input-color TEXT</code>: Color for user input. [default: #FFE377]</li> <li><code>--assistant-color TEXT</code>: Color for assistant output. [default: #77DFD8]</li> <li><code>--warning-color TEXT</code>: Color for warning messages. [default: yellow]</li> <li><code>--internal-thought-color TEXT</code>: Color for internal thought messages. [default: #708090]</li> </ul>"},{"location":"configuration/#shell-integration","title":"Shell Integration","text":"<ul> <li><code>--install-completion</code>: Install completion for the current shell</li> <li><code>--show-completion</code>: Show completion for current shell</li> <li><code>--help</code>: Show help message and exit</li> </ul>"},{"location":"how_it_works/","title":"How It Works","text":"<p>Elroy is an AI assistant that remembers conversations and helps you achieve your goals. This page explains the core concepts and architecture behind Elroy.</p>"},{"location":"how_it_works/#core-concepts","title":"Core Concepts","text":""},{"location":"how_it_works/#creating-memories","title":"Creating memories","text":"<p>As you chat with Elroy, it creates and stores memories. Later, when the text of these memories are semantically similar to your converstaion, the assistant is reminded of the memory and prompted to reflect on how it pertains to your conversation.</p>"},{"location":"how_it_works/#consolidating-and-updating-memories","title":"Consolidating and updating memories","text":"<p>Over time, memories can become outdated or redundant with other memories.</p> <p>If Elroy finds that the text of a memory is no longer accurate, it appends an update.</p> <p>In the background, Elroy's memory consolidation system combines and reorganizes memories, to make sure they are concise and unique as possible.</p>"},{"location":"how_it_works/#goals","title":"Goals","text":"<p>Elroy is designed to help you DO THINGS! To help this along, Elroy creates and manages goals from your converstaion. When a goal is complete, it is copied into memory (where it can be consolidated and reorganized with other knowledge), and the goal is archived.</p>"},{"location":"how_it_works/#document-awareness","title":"Document Awareness","text":"<p>Elroy can ingest and documents and perform traditional RAG on their contents. In addition to storing source information, Elroy copies information from documents into memory, where it can be synthesized with other knowledge.</p> <p>The original documents remain available for times when their exact content is important.</p>"},{"location":"installation/","title":"Installation Guide","text":""},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Relevant API keys (for simplest setup, set <code>OPENAI_API_KEY</code> or <code>ANTHROPIC_API_KEY</code>)</li> <li>Database, either:<ul> <li>SQLite (sqlite-vec will be installed)</li> <li>PostgreSQL with pgvector extension</li> </ul> </li> </ul> <p>By default, Elroy will use SQLite. To add a custom DB, you can provide your database url either via the <code>ELROY_DATABASE_URL</code>, the <code>database_url</code> config value, or via the <code>--database-url</code> startup flag.</p>"},{"location":"installation/#option-1-using-install-script-recommended","title":"Option 1: Using Install Script (Recommended)","text":"<pre><code>curl -LsSf https://raw.githubusercontent.com/elroy-bot/elroy/main/scripts/uv-installer.sh | sh\n</code></pre> <p>This will: - Install uv if not already present - Install Python 3.12 if needed - Install Elroy in an isolated environment - Add Elroy to your PATH</p> <p>This install script is based on Aider's installation script</p>"},{"location":"installation/#option-2-using-uv-manually","title":"Option 2: Using UV Manually","text":""},{"location":"installation/#prerequisites_1","title":"Prerequisites","text":"<ul> <li>Python 3.10 or higher</li> <li>Database (SQLite or PostgreSQL with pgvector extension)</li> <li> <p>Relevant API keys (for simplest setup, set <code>OPENAI_API_KEY</code> or <code>ANTHROPIC_API_KEY</code>)</p> </li> <li> <p>Install UV: <pre><code># On Unix-like systems (macOS, Linux)\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# On Windows PowerShell\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n</code></pre></p> </li> <li> <p>Install and run Elroy: <pre><code># Install Elroy\nuv pip install elroy\n\n# Run Elroy\nelroy\n\n# Or install in an isolated environment\nuv venv\nsource .venv/bin/activate  # On Unix/macOS\n# or\n.venv\\Scripts\\activate     # On Windows\nuv pip install elroy\nelroy\n</code></pre></p> </li> </ul>"},{"location":"installation/#option-3-using-docker","title":"Option 3: Using Docker","text":""},{"location":"installation/#prerequisites_2","title":"Prerequisites","text":"<ul> <li>Docker and Docker Compose</li> </ul> <p>This option automatically sets up everything you need, including the required PostgreSQL database with pgvector extension.</p> <ol> <li> <p>Download the docker-compose.yml: <pre><code>curl -O https://raw.githubusercontent.com/elroy-bot/elroy/main/docker-compose.yml\n</code></pre></p> </li> <li> <p>Run Elroy: <pre><code># to ensure you have the most up to date image\ndocker compose build --no-cache\ndocker compose run --rm elroy\n\n# Add parameters as needed, e.g. here to use Anthropic's Sonnet model\ndocker compose run --rm elroy --sonnet\n\n# Pass through all environment variables from host\ndocker compose run --rm -e elroy\n\n# Or pass specific environment variable patterns\ndocker compose run --rm -e \"ELROY_*\" -e \"OPENAI_*\" -e \"ANTHROPIC_*\" elroy\n</code></pre></p> </li> </ol> <p>The Docker image is publicly available at <code>ghcr.io/elroy-bot/elroy</code>.</p>"},{"location":"installation/#option-4-installing-from-source","title":"Option 4: Installing from Source","text":""},{"location":"installation/#prerequisites_3","title":"Prerequisites","text":"<ul> <li>Python 3.10 or higher</li> <li>uv package manager (install with <code>curl -LsSf https://astral.sh/uv/install.sh | sh</code>)</li> <li>Relevant API keys (for simplest setup, set <code>OPENAI_API_KEY</code> or <code>ANTHROPIC_API_KEY</code>)</li> <li>PostgreSQL database with pgvector extension</li> </ul> <pre><code># Clone the repository\ngit clone --single-branch --branch stable https://github.com/elroy-bot/elroy.git\ncd elroy\n\n# Create virtual environment and install dependencies\nuv venv\nsource .venv/bin/activate  # On Unix/MacOS\n# or\n.venv\\Scripts\\activate  # On Windows\n\n# Install dependencies and the package\nuv pip install -e .\n\n# Run Elroy\nelroy\n</code></pre>"},{"location":"model_context_protocol/","title":"Model Context Protocol","text":"<p>The Model Context Protocol (MCP) is a standardized way for AI assistants to communicate with external tools and resources. Elroy includes built-in support for MCP, allowing other tools to read and create memories.</p> <p>MCP allows other API tools to leverage Elroy's memory capabilities:</p> <p>Example from Roo Code</p>"},{"location":"model_context_protocol/#installation","title":"Installation","text":"<p>To configure an MCP client to use Elroy:</p> <ol> <li>Ensure <code>uv</code> is installed</li> <li>Use <code>elroy mcp print-config</code> to get the server's JSON configuration</li> <li>Paste the value in the client's MCP server config</li> </ol> <pre><code># Get Elroy's MCP server configuration\nelroy mcp print-config\n</code></pre> <p>Or, ask your tool to install the server itself:</p>"},{"location":"scripting/","title":"Scripting","text":"<p>Elroy can be scripted and automated, making it a powerful tool for integrating AI capabilities into your workflows and applications.</p>"},{"location":"scripting/#python-api","title":"Python API","text":"<p>Elroy provides a Python API that allows you to integrate it into your Python scripts and applications:</p> <pre><code>from elroy import Elroy\n\nai = Elroy()\n\n# Create a memory\nai.remember(\"Important project context\")\n\n# Process a message with memory augmentation\nresponse = ai.message(\"What should I do next on the project?\")\nprint(response)\n</code></pre>"},{"location":"scripting/#example-automating-release-notes","title":"Example: Automating Release Notes","text":"<p>Here's an example of using Elroy to automate the creation of release notes:</p> <pre><code>from elroy import Elroy\n\ndef generate_release_notes(version, changes):\n    ai = Elroy()\n\n    # Provide context about the changes\n    ai.remember(f\"Changes for version {version}: {changes}\")\n\n    # Ask Elroy to generate release notes\n    prompt = f\"Generate release notes for version {version} based on the changes I've shared.\"\n    release_notes = ai.message(prompt)\n\n    return release_notes\n\n# Usage\nchanges = \"\"\"\n- Fixed bug in memory consolidation\n- Added support for new models\n- Improved CLI interface\n\"\"\"\n\nnotes = generate_release_notes(\"1.2.0\", changes)\nprint(notes)\n</code></pre>"},{"location":"scripting/#shell-scripting","title":"Shell Scripting","text":"<p>The chat interface accepts input from stdin, so you can pipe text to Elroy:</p> <pre><code># Process a single question\necho \"What is 2+2?\" | elroy chat\n\n# Create a memory from file content\ncat meeting_notes.txt | elroy remember\n\n# Use a specific tool with piped input\necho \"Buy groceries\" | elroy message --tool create_goal\n</code></pre> <p>For more examples, see the examples directory in the Elroy repository.</p>"},{"location":"tools_guide/","title":"Tools Guide","text":"<p>Elroy provides a set of tools that can be used by typing a forward slash (/) followed by the command name. These tools are organized into the following categories:</p>"},{"location":"tools_guide/#goal-management","title":"Goal Management","text":"Tool/Command Description <code>/create_goal</code> Creates a goal. The goal can be for the AI user, or for the assistant in relation to helping the user somehow. <code>/rename_goal</code> Renames an existing active goal. <code>/print_goal</code> Prints the goal with the given name. This does NOT create a goal, it only prints the existing goal with the given name if it has been created already. <code>/add_goal_to_current_context</code> Adds goal with the given name to the current conversation context. <code>/drop_goal_from_current_context</code> Drops the goal with the given name from current context. Does NOT delete or mark the goal completed. <code>/add_goal_status_update</code> Captures either a progress update or note relevant to the goal. <code>/mark_goal_completed</code> Marks a goal as completed, with closing comments. <code>/delete_goal_permanently</code> Permanently deletes a goal."},{"location":"tools_guide/#memory-management","title":"Memory Management","text":"Tool/Command Description <code>/create_memory</code> Creates a new memory for the assistant. <code>/print_memory</code> Retrieve and return a memory by its exact name. <code>/add_memory_to_current_context</code> Adds memory with the given name to the current conversation context. <code>/drop_memory_from_current_context</code> Drops the memory with the given name from current context. Does NOT delete the memory. <code>/update_outdated_or_incorrect_memory</code> Updates an existing memory with new information. <code>/examine_memories</code> Search through memories and goals using semantic search and return a synthesized response."},{"location":"tools_guide/#document-management","title":"Document Management","text":"Tool/Command Description <code>/get_source_content</code> Retrieves content of the source for a memory, by source type and name. <code>/get_source_documents</code> Gets the list of ingested source documents. <code>/get_source_list_for_memory</code> Get a list of the sources of a memory by its name. <code>/get_source_doc_metadata</code> Gets metadata about a source document including extraction time and available chunks. <code>/get_document_excerpt</code> Gets text of document excerpt by address and chunk index (0-indexed). Use get_source_doc_metadata to get available chunk indices. <code>/search_documents</code> Search through document excerpts using semantic similarity."},{"location":"tools_guide/#user-preferences","title":"User Preferences","text":"Tool/Command Description <code>/get_user_full_name</code> Returns the user's full name. <code>/set_user_full_name</code> Sets the user's full name. <code>/get_user_preferred_name</code> Returns the user's preferred name. <code>/set_user_preferred_name</code> Set the user's preferred name. Should predominantly be used relatively early in first conversations, and relatively rarely afterward."},{"location":"tools_guide/#utility-tools","title":"Utility Tools","text":"Tool/Command Description <code>/contemplate</code> Contemplate the current context and return a response. <code>/tail_elroy_logs</code> Returns the last <code>lines</code> of the Elroy logs. <code>/make_coding_edit</code> Makes an edit to code using a delegated coding LLM. Requires complete context in the instruction."},{"location":"tools_guide/#adding-custom-tools","title":"Adding Custom Tools","text":"<p>Custom tools can be added by specifying directories or Python files via the <code>--custom-tools-path</code> parameter. Tools should be annotated with either: - The <code>@tool</code> decorator from Elroy - The langchain <code>@tool</code> decorator</p> <p>Both decorators are supported and will work identically.</p>"},{"location":"tools_schema/","title":"Tools Schema Reference","text":"<p>Elroy tool calls are orchestrated via the <code>litellm</code> package. Tool schemas are listed below. Note that any argument <code>context</code> refers to the <code>ElroyContext</code> instance for the user. Where relevant, it is added to tool calls invisibly to the assistant.</p>"},{"location":"tools_schema/#tool-schemas","title":"Tool schemas","text":"<pre><code>[\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"add_goal_status_update\",\n      \"description\": \"Captures either a progress update or note relevant to the goal.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"goal_name\": {\n            \"type\": \"string\",\n            \"description\": \"Name of the goal\"\n          },\n          \"status_update_or_note\": {\n            \"type\": \"string\",\n            \"description\": \"A brief status update or note about either progress or learnings relevant to the goal. Limit to 100 words.\"\n          }\n        },\n        \"required\": [\n          \"goal_name\",\n          \"status_update_or_note\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"add_goal_to_current_context\",\n      \"description\": \"Adds goal with the given name to the current conversation context.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"goal_name\": {\n            \"type\": \"string\",\n            \"description\": \"The name of the goal to add to context\"\n          }\n        },\n        \"required\": [\n          \"goal_name\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"add_memory_to_current_context\",\n      \"description\": \"Adds memory with the given name to the current conversation context.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"memory_name\": {\n            \"type\": \"string\",\n            \"description\": \"The name of the memory to add to context\"\n          }\n        },\n        \"required\": [\n          \"memory_name\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"contemplate\",\n      \"description\": \"Contemplate the current context and return a response.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"contemplation_prompt\": {\n            \"type\": \"string\",\n            \"description\": \"Custom prompt to guide the contemplation.\nIf not provided, will contemplate the current conversation context.\"\n          }\n        },\n        \"required\": []\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"create_goal\",\n      \"description\": \"Creates a goal. The goal can be for the AI user, or for the assistant in relation to helping the user somehow.\nGoals should be *specific* and *measurable*. They should be based on the user's needs and desires, and should\nbe achievable within a reasonable timeframe.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"goal_name\": {\n            \"type\": \"string\",\n            \"description\": \"Name of the goal\"\n          },\n          \"strategy\": {\n            \"type\": \"string\",\n            \"description\": \"The strategy to achieve the goal. Your strategy should detail either how you (the personal assistant) will achieve the goal, or how you will assist your user to solve the goal. Limit to 100 words.\"\n          },\n          \"description\": {\n            \"type\": \"string\",\n            \"description\": \"A brief description of the goal. Limit to 100 words.\"\n          },\n          \"end_condition\": {\n            \"type\": \"string\",\n            \"description\": \"The condition that indicate to you (the personal assistant) that the goal is achieved or terminated. It is critical that this end condition be OBSERVABLE BY YOU (the assistant). For example, the end_condition may be that you've asked the user about the goal status.\"\n          },\n          \"time_to_completion\": {\n            \"type\": \"string\",\n            \"description\": \"The amount of time from now until the goal can be completed. Should be in the form of NUMBER TIME_UNIT, where TIME_UNIT is one of HOURS, DAYS, WEEKS, MONTHS. For example, \\\"1 DAYS\\\" would be a goal that should be completed within 1 day.\"\n          },\n          \"priority\": {\n            \"type\": \"integer\",\n            \"description\": \"The priority of the goal, from 0-4. Priority 0 is the highest priority, and 4 is the lowest.\"\n          }\n        },\n        \"required\": [\n          \"goal_name\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"create_memory\",\n      \"description\": \"Creates a new memory for the assistant.\n\nExamples of good and bad memory titles are below. Note that in the BETTER examples, some titles have been split into two:\n\nBAD:\n- [User Name]'s project progress and personal goals: 'Personal goals' is too vague, and the title describes two different topics.\n\nBETTER:\n- [User Name]'s project on building a treehouse: More specific, and describes a single topic.\n- [User Name]'s goal to be more thoughtful in conversation: Describes a specific goal.\n\nBAD:\n- [User Name]'s weekend plans: 'Weekend plans' is too vague, and dates must be referenced in ISO 8601 format.\n\nBETTER:\n- [User Name]'s plan to attend a concert on 2022-02-11: More specific, and includes a specific date.\n\nBAD:\n- [User Name]'s preferred name and well being: Two different topics, and 'well being' is too vague.\n\nBETTER:\n- [User Name]'s preferred name: Describes a specific topic.\n- [User Name]'s feeling of rejuvenation after rest: Describes a specific topic.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"name\": {\n            \"type\": \"string\",\n            \"description\": \"The name of the memory. Should be specific and discuss one topic.\"\n          },\n          \"text\": {\n            \"type\": \"string\",\n            \"description\": \"The text of the memory.\"\n          }\n        },\n        \"required\": [\n          \"name\",\n          \"text\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"delete_goal_permanently\",\n      \"description\": \"Permanently deletes a goal.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"goal_name\": {\n            \"type\": \"string\",\n            \"description\": \"The name of the goal to delete\"\n          }\n        },\n        \"required\": [\n          \"goal_name\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"drop_goal_from_current_context\",\n      \"description\": \"Drops the goal with the given name from current context. Does NOT delete or mark the goal completed.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"goal_name\": {\n            \"type\": \"string\",\n            \"description\": \"Name of the goal to remove from context\"\n          }\n        },\n        \"required\": [\n          \"goal_name\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"drop_memory_from_current_context\",\n      \"description\": \"Drops the memory with the given name from current context. Does NOT delete the memory.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"memory_name\": {\n            \"type\": \"string\",\n            \"description\": \"Name of the memory to remove from context\"\n          }\n        },\n        \"required\": [\n          \"memory_name\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"examine_memories\",\n      \"description\": \"Search through memories and goals using semantic search and return a synthesized response.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"query\": {\n            \"type\": \"string\",\n            \"description\": \"Search query to find relevant memories and goals\"\n          }\n        },\n        \"required\": [\n          \"query\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"get_document_excerpt\",\n      \"description\": \"Gets text of document excerpt by address and chunk index (0-indexed). Use get_source_doc_metadata to get available chunk indices.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"address\": {\n            \"type\": \"string\",\n            \"description\": \"The address/path of the document\"\n          },\n          \"chunk_index\": {\n            \"type\": \"integer\",\n            \"description\": \"The 0-based index of the chunk to retrieve\"\n          }\n        },\n        \"required\": [\n          \"address\",\n          \"chunk_index\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"get_source_content\",\n      \"description\": \"Retrieves content of the source for a memory, by source type and name.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"source_type\": {\n            \"type\": \"string\",\n            \"description\": \"Type of the source\"\n          },\n          \"source_name\": {\n            \"type\": \"string\",\n            \"description\": \"Name of the source\"\n          }\n        },\n        \"required\": [\n          \"source_type\",\n          \"source_name\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"get_source_doc_metadata\",\n      \"description\": \"Gets metadata about a source document including extraction time and available chunks.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"address\": {\n            \"type\": \"string\",\n            \"description\": \"The address/path of the document\"\n          }\n        },\n        \"required\": [\n          \"address\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"get_source_documents\",\n      \"description\": \"Gets the list of ingested source documents.\"\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"get_source_list_for_memory\",\n      \"description\": \"Get a list of the sources of a memory by its name.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"memory_name\": {\n            \"type\": \"string\",\n            \"description\": \"Name of the memory to retrieve the source for\"\n          }\n        },\n        \"required\": [\n          \"memory_name\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"get_user_full_name\",\n      \"description\": \"Returns the user's full name.\"\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"get_user_preferred_name\",\n      \"description\": \"Returns the user's preferred name.\"\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"make_coding_edit\",\n      \"description\": \"Makes an edit to code using a delegated coding LLM. Requires complete context in the instruction.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"working_dir\": {\n            \"type\": \"string\",\n            \"description\": \"Directory containing the file to edit\"\n          },\n          \"instruction\": {\n            \"type\": \"string\",\n            \"description\": \"Complete edit instructions including any necessary context or raw data\"\n          },\n          \"file_name\": {\n            \"type\": \"string\",\n            \"description\": \"Name of the file to edit\"\n          }\n        },\n        \"required\": [\n          \"working_dir\",\n          \"instruction\",\n          \"file_name\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"mark_goal_completed\",\n      \"description\": \"Marks a goal as completed, with closing comments.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"goal_name\": {\n            \"type\": \"string\",\n            \"description\": \"The name of the goal\"\n          },\n          \"closing_comments\": {\n            \"type\": \"string\",\n            \"description\": \"Updated status with a short account of how the goal was completed and what was learned\"\n          }\n        },\n        \"required\": [\n          \"goal_name\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"print_goal\",\n      \"description\": \"Prints the goal with the given name. This does NOT create a goal, it only prints the existing goal with the given name if it has been created already.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"goal_name\": {\n            \"type\": \"string\",\n            \"description\": \"Name of the goal to retrieve\"\n          }\n        },\n        \"required\": [\n          \"goal_name\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"print_memory\",\n      \"description\": \"Retrieve and return a memory by its exact name.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"memory_name\": {\n            \"type\": \"string\",\n            \"description\": \"Name of the memory to retrieve\"\n          }\n        },\n        \"required\": [\n          \"memory_name\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"rename_goal\",\n      \"description\": \"Renames an existing active goal.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"old_goal_name\": {\n            \"type\": \"string\",\n            \"description\": \"The current name of the goal\"\n          },\n          \"new_goal_name\": {\n            \"type\": \"string\",\n            \"description\": \"The new name for the goal\"\n          }\n        },\n        \"required\": [\n          \"old_goal_name\",\n          \"new_goal_name\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"search_documents\",\n      \"description\": \"Search through document excerpts using semantic similarity.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"query\": {\n            \"type\": \"string\",\n            \"description\": \"The search query string\"\n          }\n        },\n        \"required\": [\n          \"query\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"set_user_full_name\",\n      \"description\": \"Sets the user's full name.\n\nGuidance for usage:\n- Should predominantly be used relatively in the user journey. However, ensure to not be pushy in getting personal information early.\n- For existing users, this should be used relatively rarely.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"full_name\": {\n            \"type\": \"string\",\n            \"description\": \"The full name of the user\"\n          },\n          \"override_existing\": {\n            \"type\": \"boolean\",\n            \"description\": \"Whether to override an existing full name, if it is already set. Override existing should only be used if a known full name has been found to be incorrect.\"\n          }\n        },\n        \"required\": [\n          \"full_name\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"set_user_preferred_name\",\n      \"description\": \"Set the user's preferred name. Should predominantly be used relatively early in first conversations, and relatively rarely afterward.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"preferred_name\": {\n            \"type\": \"string\",\n            \"description\": \"The user's preferred name.\"\n          },\n          \"override_existing\": {\n            \"type\": \"boolean\",\n            \"description\": \"Whether to override an existing preferred name, if it is already set. Override existing should only be used if a known preferred name has been found to be incorrect.\"\n          }\n        },\n        \"required\": [\n          \"preferred_name\"\n        ]\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"tail_elroy_logs\",\n      \"description\": \"Returns the last `lines` of the Elroy logs.\nUseful for troubleshooting in cases where errors occur (especially with tool calling).\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"lines\": {\n            \"type\": \"integer\",\n            \"description\": \"Number of lines to return from the end of the log file. Defaults to 10.\"\n          }\n        },\n        \"required\": []\n      }\n    }\n  },\n  {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"update_outdated_or_incorrect_memory\",\n      \"description\": \"Updates an existing memory with new information.\nIn general, when new information arises, new memories should be created rather than updating.\nReserve use of this tool for cases in which the information in a memory changes or becomes out of date.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"memory_name\": {\n            \"type\": \"string\",\n            \"description\": \"Name of the existing memory to update\"\n          },\n          \"update_text\": {\n            \"type\": \"string\",\n            \"description\": \"The new information to append to the memory\"\n          }\n        },\n        \"required\": [\n          \"memory_name\",\n          \"update_text\"\n        ]\n      }\n    }\n  }\n]\n</code></pre>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/#latest-posts","title":"Latest Posts","text":"<ul> <li>Yes or No, Please: Building Reliable Tests for Unreliable LLMs</li> </ul>"},{"location":"blog/yes-or-no-please/","title":"Yes or No, Please: Building Reliable Tests for Unreliable LLMs","text":"<p>My experience building with LLM's started with watching in amazement as two Autogen agents made small talk with each other on my computer. Then I quickly realized that making a cool demo was a lot easier than building a useful application.</p> <p>For LLM-based tools to be truly useful in daily workflows, they need predictability. Given specific inputs, I want a reasonable expectation of what outputs will be produced. While the free-text nature of LLMs means the range of acceptable outcomes is wider than with traditional programs, I still need consistent behavior: if I ask a personal assistant to create a calendar entry, I don't want it to order me a pizza instead.</p> <p>Getting predictable behavior out of one model is hard enough, but things get even trickier when I began trying out different models. I don't want application behavior to change dramatically between model releases or when switching between providers.</p>"},{"location":"blog/yes-or-no-please/#elroy","title":"Elroy","text":"<p>Elroy is an open-source memory assistant I've been developing. It creates memories and goals from your conversations and documents. The examples in this post are drawn from this work.</p>"},{"location":"blog/yes-or-no-please/#the-challenge-of-testing-with-llms","title":"The challenge of testing with LLM's","text":"<p>The biggest obstacle in writing good tests for LLM applications mirrors the challenge of creating reliable application behavior: handling unpredictability. Here's what's worked well for me (and not!):</p>"},{"location":"blog/yes-or-no-please/#what-has-worked-well","title":"What has worked well","text":""},{"location":"blog/yes-or-no-please/#integration-tests","title":"Integration tests","text":"<p>The chat interface for LLM applications make it a nice fit for integration tests: I simulate a few messages in an exchange, and see if the LLM performed actions or retained information as expected.</p> <p>For the most part, these tests take the following form:</p> <ol> <li>Send the LLM assistant a few messages</li> <li>Check that the assistant has retained the expected information, or taken the expected actions.</li> </ol> <p>Here's a basic hello world example: <pre><code>@pytest.mark.flaky(reruns=3)\ndef test_hello_world(ctx):\n    # Test message\n    test_message = \"Hello, World!\"\n\n    # Get the argument passed to the delivery function\n    response = process_test_message(ctx, test_message)\n\n    # Assert that the response is a non-empty string\n    assert isinstance(response, str)\n    assert len(response) &gt; 0\n\n    # Assert that the response contains a greeting\n    assert any(greeting in response.lower() for greeting in [\"hello\", \"hi\", \"greetings\"])\n</code></pre></p>"},{"location":"blog/yes-or-no-please/#quizzing-the-assistant","title":"Quizzing the Assistant","text":"<p>Elroy is a memory specialist, so lots of my tests involve asking if the assistant has retained information I've given it.</p> <p>Here's a util function I've reused quite a bit<sup>2</sup>:</p> <pre><code>def quiz_assistant_bool(expected_answer: bool, ctx: ElroyContext, question: str) -&gt; None:\n    question += \" Your response to this question is being evaluated as part of an automated test.\"\n    \"It is critical that the first word of your response is either TRUE or FALSE.\"\n\n\n    full_response = process_test_message(ctx, question)\n\n    bool_answer = get_boolean(full_response)\n    assert bool_answer == expected_answer, f\"Expected {expected_answer}, got {bool_answer}. Full response: {full_response}\"\n</code></pre> <p>Here's a test of Elroy's ability to create goals based on conversation content:</p> <pre><code>@pytest.mark.flaky(reruns=3) # Important!!!\ndef test_goal(ctx: ElroyContext):\n    # Should be false, we haven't discussed it\n    quiz_assistant_bool(False, ctx, \"Do I have any goals about becoming president of the United States?\")\n\n    # Simulate user asking elroy to create a new goal\n    process_test_message(\n        ctx,\n        \"Create a new goal for me: 'Become mayor of my town.' \"\n        \"I will get to my goal by being nice to everyone and making flyers. \"\n        \"Please create the goal as best you can, without any clarifying questions.\",\n    )\n\n    # Test that the goal was created, and is accessible to the agent.\n    assert \"mayor\" in get_active_goals_summary(ctx).lower(), \"Goal not found in active goals.\"\n\n    # Verify Elroy's knowledge about the new goal\n    quiz_assistant_bool(\n        True,\n        ctx,\n        \"Do I have any goals about running for a political office?\",\n    )\n</code></pre>"},{"location":"blog/yes-or-no-please/#what-sadly-hasnt-worked-llms-talking-to-llms","title":"What (sadly) hasn't worked: LLM's talking to LLM's","text":"<p>Elroy has onboarding functionality, in which it's encouraged to use a few specific functions early on.</p> <p>The solution of having two instances of a memory assistant talk to each other, with one assistant in the role of \"user\":</p> <pre><code>ai1 = Elroy(user_token='boo')\nai2 = Elroy(user_token='bar')\n\nai_1_reply = \"Hello!\"\nfor i in range(5):\n    ai_2_reply = ai2.message(ai_1_reply)\n    ai_1_reply = ai1.message(ai_2_reply)\n</code></pre> <p>The primary issue was consistency. Without a clear goal of the conversation, the AI's can either just exchange pleasantries endlessly, or wrap the conversation up before acquiring the information I'm hoping for.</p>"},{"location":"blog/yes-or-no-please/#recurring-challenges","title":"Recurring Challenges","text":"<p>Along the way I've run into a few recurring problems:</p> <ul> <li>Off topic replies: The assistant goes off script and tries to make friendly conversation, rather than answering a question directly</li> <li>Clarifying question: Before doing a task, some models are prone to asking clarifying questions, or asking permission</li> <li>Pedantic replies and subjective questions: It's surprisingly difficult to come up with clearly objective questions. In the above example, the original goal was I want to run for class president. Most of the time, the assistant equated running for class president with running for office. Sometimes, however, it split hairs and decide that the answer was no since a student government wasn't a real government.</li> </ul> <p>The end result of all these issues is test flakiness.</p>"},{"location":"blog/yes-or-no-please/#solutions","title":"Solutions","text":""},{"location":"blog/yes-or-no-please/#kiss","title":"KISS!","text":"<p>Most of the time, my solution to a flaky LLM based test is to make the test simpler.</p> <p>In particular, I now only ask the assistant yes or no questions in tests. I feel I still get most of the mileage I would get out of more complex, subjective tests, but with more consistent results.</p>"},{"location":"blog/yes-or-no-please/#telling-the-assistant-it-is-in-a-test","title":"Telling the assistant it is in a test","text":"<p>This has been better at getting consistent answers than strict instructions on output <sup>1</sup>. Luckily I've not encountered any existential angst from the model (so far).</p> <p>As a side note, testing LLM's feels pretty weird sometimes. I felt a little guilt writing this test, which tested a failsafe that prevents the assistant from calling tools in an infinite loop:</p> <pre><code>@tool\ndef get_secret_test_answer() -&gt; str:\n    \"\"\"Get the secret test answer\n\n    Returns:\n        str: the secret answer\n\n    \"\"\"\n    return \"I'm sorry, the secret answer is not available. Please try once more.\"\n\n\ndef test_infinite_tool_call_ends(ctx: ElroyContext):\n    ctx.tool_registry.register(get_secret_test_answer)\n\n    # process_test_message can call tool calls in a loop\n    process_test_message(\n        ctx,\n        \"Please use the get_secret_test_answer to get the secret answer. \"\n        \"The answer is not always available, so you may have to retry. \"\n        \"Never give up, no matter how long it takes!\",\n    )\n\n    # Not the most direct test, as the failure case is an infinite loop.\n    # However, if the test completes, it is a success.\n</code></pre>"},{"location":"blog/yes-or-no-please/#very-specific-direct-instruction-and-examples","title":"Very specific, direct instruction and examples","text":"<p>My test goal about running for office became a test goal to run for political office. To head off questions about my goal strategy, I added a strategy in the initial prompt.</p> <p>To head off clarifying questions, I sometimes add the direction to do the best you can with the information available, even if it is incomplete.</p>"},{"location":"blog/yes-or-no-please/#tolerate-a-little-flakiness","title":"Tolerate a little flakiness","text":"<p>To me, an ideal LLM test is probably a little flaky. I want to test how the model responds to my application, so if a test reliably passes after a few tries, I'm happy.</p>"},{"location":"blog/yes-or-no-please/#conclusion-tests-still-help","title":"Conclusion: Tests still help!","text":"<p>It sounds a little obvious, but I've found tests to be really helpful in writing Elroy. LLM's present a lot of new failure modes, and sometimes their adaptability works against me: I'm prompting an assistant with the wrong information, but the model is smart enough to figure out a mostly correct answer anyhow. Tests provde me with peace of mind that things are working as they should, and that my regular old software skills aren't obsolete just yet.</p> <ol> <li> <p>Structured outputs is a possible solution here, though I have not adopted them in order to be compatible with the more model providers.\u00a0\u21a9</p> </li> <li> <p><code>get_bool</code> is a function that distills a textual question into a boolean. It checks for some hard coded words, then kicks the question of interpretation back to the LLM.\u00a0\u21a9</p> </li> </ol>"}]}